# **Environment Setup and Data Prepare**
This project is based on the Tensorflow Object Detection and the dataset is download from [cvdfoundation](https://github.com/cvdfoundation/open-images-dataset#download-images-with-bounding-boxes-annotations), you can follow the below step to reconstruct this project.

## Setup Tensorflow Object Api
Follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) of Tensorflow Object Detection.

## Download pretrained weight
I use the pretrained weight of [kwea/123](https://github.com/kwea123/fish_detection/tree/master/data), which has already existed in /models/research/object_detection/data.


# **Project Execution**
## With Jupyter notebook
put the ipynb files under /models/research/object_detection/
run the desired notebook files
<!-- run final-webcam-video.ipynb in /models/research/object_detection/. -->

<!-- ## Without Jupyter notebook -->
<!-- run final-webcam-video.py in /models/research/object_detection/. -->


# **Sample output video**
This is the [sample output](https://www.youtube.com/watch?v=CAiTHfaG7ww&feature=youtu.be).